{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alignment-Lab-AI/AutoMeticAssistant/blob/main/FastLanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86tDFezpBnRR",
        "outputId": "faae57b2-473b-4a60-be8f-aa23ec85466e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-26 23:16:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.34.83, 13.226.34.53, 13.226.34.7, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.34.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  78.4MB/s    in 15s     \n",
            "\n",
            "2023-12-26 23:16:59 (99.9 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "7JRUNk4oHotm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bc4063-0fdb-4503-b6be-4bcb3ee6c13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers  fasttext datasets"
      ],
      "metadata": {
        "id": "-JfYc76OCfvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "metadata": {
        "id": "DjQvBS6MCqDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd fastText"
      ],
      "metadata": {
        "id": "EJPZtkiACwR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo python setup.py install"
      ],
      "metadata": {
        "id": "2suKerd8C0Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "3RuDD8-SC2ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./../"
      ],
      "metadata": {
        "id": "yuhn913zC6Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"Open-Orca/OpenOrca\")['all']\n",
        "dataset = dataset.select(range(5000))\n",
        "\n",
        "with open('./train.txt', 'w', encoding='utf-8') as file:\n",
        "    for conversation in dataset:\n",
        "        # Initialize a temporary string to hold the conversation text\n",
        "        conversation_text = ''\n",
        "        for turn in conversation['conversation']:\n",
        "            # Check the 'from' field to determine if it's a prompt or a response\n",
        "            if turn['from'] in ['system', 'human']:\n",
        "                # Add the prompt to the conversation text\n",
        "                conversation_text += turn['value'] + '\\n'\n",
        "            elif turn['from'] == 'gpt':\n",
        "                # Add the response to the conversation text\n",
        "                conversation_text += turn['value'] + '\\n\\n'\n",
        "        # Write the processed conversation to the file\n",
        "        file.write(conversation_text)\n"
      ],
      "metadata": {
        "id": "CSu_5dAtD-VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
        "        n=0\n",
        "        for line in f:\n",
        "            n=n+1\n",
        "            if n<50000:\n",
        "             values = line.strip().split(' ')\n",
        "             word = values[0]\n",
        "             vector = [float(val) for val in values[1:]]\n",
        "             embeddings[word] = vector\n",
        "    return embeddings\n",
        "def reduce_dimensionality(embeddings, n_components=32):\n",
        "    reduced_embeddings = {}\n",
        "    for i, (word, vector) in enumerate(embeddings.items()):\n",
        "        if i >= 50000:\n",
        "            break\n",
        "        reduced_vector = vector[:n_components]\n",
        "        reduced_embeddings[word] = reduced_vector\n",
        "    return reduced_embeddings\n",
        "\n",
        "def save_embeddings(embeddings, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for word, vector in embeddings.items():\n",
        "            vector_str = ' '.join(str(val) for val in vector)\n",
        "            f.write(f'{word} {vector_str}\\n')\n",
        "\n",
        "input_file = '/content/crawl-300d-2M.vec.zip'\n",
        "output_file = 'reduced_embeddings_32d_50k.vec'\n",
        "embeddings = load_embeddings(input_file)\n",
        "reduced_embeddings = reduce_dimensionality(embeddings, n_components=32)\n",
        "save_embeddings(reduced_embeddings, output_file)\n"
      ],
      "metadata": {
        "id": "11F0Q7TDPmmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to load the first 50,000 words\n",
        "def load_top_words(filename, limit=50000):\n",
        "    vocab = {}\n",
        "    with open(filename, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            tokens = line.rstrip().split(' ')\n",
        "            word = tokens[0]\n",
        "            if word not in vocab:\n",
        "                vocab[word] = len(vocab) + 1  # assign an index to each word\n",
        "            if len(vocab) >= limit:\n",
        "                break\n",
        "    return vocab\n",
        "\n",
        "# Load the top 50,000 words\n",
        "vocab = load_top_words('/content/reduced_embeddings_32d_50k.vec')\n"
      ],
      "metadata": {
        "id": "vnEy1u8WEEEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process your text file\n",
        "data = []\n",
        "with open('./train.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        words = line.strip().split()\n",
        "        for i, word in enumerate(words):\n",
        "            # Check if the word is in the vocabulary\n",
        "            if word not in vocab:\n",
        "                word = '<unk>'\n",
        "            if i > 0:\n",
        "                # Use double quotes for the f-string and single quotes inside it\n",
        "                label = f\"__label__{words[i-1]}\"\n",
        "                # Use  words or '<unk>' if they are not in vocab\n",
        "                context = ' '.join(words)\n",
        "                labelled_example = f\"{label} {context}\"\n",
        "                data.append(labelled_example)\n",
        "\n",
        "# Write the data to the output file\n",
        "with open('./ft.txt', 'w') as file:\n",
        "    file.write('\\n'.join(data))\n"
      ],
      "metadata": {
        "id": "INKngASNSEs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_first_line(file_path, new_first_line):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Substitua a primeira linha\n",
        "    lines[0] = new_first_line + '\\n'\n",
        "\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "# Caminho para o arquivo \"crawl-300d-2M.vec\"\n",
        "file_path = '/content/reduced_embeddings_32d_50k.vec'\n",
        "\n",
        "# Nova primeira linha\n",
        "new_first_line = '50000 32'\n",
        "\n",
        "# Edite a primeira linha\n",
        "edit_first_line(file_path, new_first_line)\n"
      ],
      "metadata": {
        "id": "dg8gQUBtQW7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXBOJ--kRsYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GOOD QUALITY = 500 epochs\n",
        "NORMAL QUALITY  = 5 epochs"
      ],
      "metadata": {
        "id": "FLOYBfLARtss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./fastText/fasttext  supervised -input ft.txt -output model -loss ns -dim 32 -lr .5 -epoch 5   -pretrainedVectors /content/reduced_embeddings_32d_50k.vec"
      ],
      "metadata": {
        "id": "SFk6iVBGE9Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a trained FastText model\n",
        "model = fasttext.load_model('model.bin')\n",
        "\n",
        "def apply_repetition_penalty(labels, probabilities, used_labels, penalty_scale=1.9):\n",
        "    \"\"\"\n",
        "    Applies a repetition penalty to reduce the probability of already used labels.\n",
        "\n",
        "    :param labels: List of possible labels.\n",
        "    :param probabilities: Corresponding list of probabilities.\n",
        "    :param used_labels: Set of labels that have already been used.\n",
        "    :param penalty_scale: Scale of the penalty to be applied.\n",
        "    :return: Adjusted probabilities.\n",
        "    \"\"\"\n",
        "    adjusted_probabilities = probabilities.copy()\n",
        "    for i, label in enumerate(labels):\n",
        "        if label in used_labels:\n",
        "            adjusted_probabilities[i] /= penalty_scale\n",
        "    # Normalize the probabilities to sum to 1 again\n",
        "    adjusted_probabilities /= adjusted_probabilities.sum()\n",
        "    return adjusted_probabilities\n",
        "\n",
        "def predict_sequence(model, text, sequence_length=20, temperature=.9, penalty_scale=1.5):\n",
        "    \"\"\"\n",
        "    Generates a sequence of labels using the FastText model with repetition penalty.\n",
        "\n",
        "    :param model: Loaded FastText model.\n",
        "    :param text: Initial text to start the prediction from.\n",
        "    :param sequence_length: Desired length of the sequence.\n",
        "    :param temperature: Temperature for sampling.\n",
        "    :param penalty_scale: Scale of repetition penalty.\n",
        "    :return: List of predicted labels.\n",
        "    \"\"\"\n",
        "    used_labels = set()\n",
        "    sequence = []\n",
        "\n",
        "    for _ in range(sequence_length):\n",
        "        # Predict the top k most probable labels\n",
        "        labels, probabilities = model.predict(text, k=40)\n",
        "        labels = [label.replace('__label__', '') for label in labels]\n",
        "        probabilities = np.array(probabilities)\n",
        "\n",
        "        # Adjust the probabilities with repetition penalty\n",
        "        probabilities = apply_repetition_penalty(labels, probabilities, used_labels, penalty_scale)\n",
        "\n",
        "        # Sampling according to the adjusted probabilities\n",
        "        label_index = np.random.choice(range(len(labels)), p=probabilities)\n",
        "        chosen_label = labels[label_index]\n",
        "\n",
        "        # Add the chosen label to the sequence and to the set of used labels\n",
        "        sequence.append(chosen_label)\n",
        "        used_labels.add(chosen_label)\n",
        "\n",
        "        # Update the text with the chosen label for the next prediction\n",
        "        text += ' ' + chosen_label\n",
        "\n",
        "    return sequence\n",
        "\n",
        "# Example usage\n",
        "generated_sequence = predict_sequence(model, \"How do you create an opinion poll?\", sequence_length=50)\n",
        "\n",
        "print(\"How do you create an opinion poll?\")\n",
        "print(' '.join(generated_sequence))\n",
        "\n",
        "generated_sequence = predict_sequence(model, \"What is a language model for?\", sequence_length=50)\n",
        "\n",
        "print(\"What is a language model for?\")\n",
        "print(' '.join(generated_sequence))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RVUG90KYGYqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}